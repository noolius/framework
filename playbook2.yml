---
  - name: Provisioning Alpine 3.14 K8s (all, post-first reboot)
    hosts: "*"
    become: yes
    tasks:
      - name: Adding node IP to /e/hosts
        blockinfile:
          block: '{{ ansible_eth1.ipv4.address | quote }}   {{ ansible_hostname | quote }} {{ ansible_hostname | quote }}.local'
          path: /etc/hosts
      - name: Removing extraneous loopback entry from /e/hosts
        lineinfile:
          state: absent
          regexp: '^127\.0\.1\.1'
          path: /etc/hosts
      - name: Getting images corresponding to kubeadm version
        ansible.builtin.command: /usr/bin/kubeadm config images pull
  - name: Provisioning Alpine 3.14 K8s (control-planes, post-first reboot)
    hosts: control_planes
    become: yes
    vars:
      apiserver: 192.168.133.10
      k8s_serviceport: 6443
    tasks:
      - name: Creating KUBECONFIG dir for root user
        file:
          path: /root/.kube
          state: directory
          owner: root
          group: root
          mode: '0750'
      - name: Creating KUBECONFIG dir for vagrant user
        file:
          path: /home/vagrant/.kube
          state: directory
          owner: vagrant
          group: vagrant
          mode: '0750'
      - name: Creating K8s manifests with api-server on internal (to-VMs) LAN
        ansible.builtin.shell: nohup /usr/bin/kubeadm init --apiserver-advertise-address={{ apiserver | quote }} --skip-phases=addon/kube-proxy </dev/null >/vagrant/text 2>&1 &
        args:
          executable: /bin/bash
      - name: Waiting for /v/lib/kubelet/kubeadm-flags.env
        wait_for:
          path: /var/lib/kubelet/kubeadm-flags.env
          search_regex: pause
      - name: Replacing KUBELET_EXTRA_ARGS
        # openrc service file in Alpine Linux uses KUBELET_KUBEADM_ARGS; also needs cgroupfs
        lineinfile:
          line: 'KUBELET_KUBEADM_ARGS="--node-ip {{ ansible_eth1.ipv4.address | quote }} --container-runtime remote --container-runtime-endpoint=/run/containerd/containerd.sock --cgroup-driver=cgroupfs --pod-infra-container-image=k8s.gcr.io/pause:3.5"'
          regexp: '^KUBELET_KUBEADM_ARGS='
          path: /var/lib/kubelet/kubeadm-flags.env
          backup: yes
      - name: Restarting kubelet
        service:
          name: kubelet
          state: restarted
      - name: Waiting for /e/kubernetes/admin.conf
        wait_for:
          path: /etc/kubernetes/admin.conf
      - name: Copying KUBECONFIG for root user
        copy:
          src: /etc/kubernetes/admin.conf
          dest: /root/.kube/config
          owner: root
          group: root
          mode: '0400'
          remote_src: yes
      - name: Copying KUBECONFIG for vagrant user
        copy:
          src: /etc/kubernetes/admin.conf
          dest: /home/vagrant/.kube/config
          owner: vagrant
          group: vagrant
          mode: '0400'
          remote_src: yes
      - name: Adding Cilium's Helm charts
        ansible.builtin.shell: KUBECONFIG=/etc/kubernetes/admin.conf /usr/local/bin/helm repo add cilium https://helm.cilium.io/
      - name: Updating Helm repos
        ansible.builtin.shell: KUBECONFIG=/etc/kubernetes/admin.conf /usr/local/bin/helm repo update
      - name: Waiting for api-server (delaying 10s)
        wait_for:
          port: '{{ k8s_serviceport | quote }}'
        delay: 10
      - name: Installing Cilium using its Helm chart
        ansible.builtin.shell: KUBECONFIG=/etc/kubernetes/admin.conf /usr/local/bin/helm install cilium cilium/cilium --version 1.10.3 --namespace kube-system --set kubeProxyReplacement=strict --set k8sServiceHost={{ apiserver | quote }} --set k8sServicePort={{ k8s_serviceport | quote }} --set l7Proxy=false --set encryption.enabled=true --set encryption.type=wireguard
        args:
          executable: /bin/bash
  - name: Provisioning Alpine 3.14 K8s (workers, post-first reboot)
    hosts: workers
    become: yes
    vars:
      apiserver: 192.168.133.10
      k8s_serviceport: 6443
    tasks:
      - name: Waiting for node registration token and hash
        wait_for:
          path: /vagrant/text
          search_regex: 'sha256'
      - name: Setting node registration token
        ansible.builtin.shell: awk '/^kubeadm/ {print $5}' /vagrant/text
        args:
          executable: /bin/bash
        register: token
      - set_fact:
          token={{ token.stdout }}
      - name: Setting node registration hash
        ansible.builtin.shell: "awk -F: '/sha256/ {gsub(/ /, \"\", $0);print $2}' /vagrant/text"
        args:
          executable: /bin/bash
        register: ca_cert_hash
      - set_fact:
          ca_cert_hash={{ ca_cert_hash.stdout }}
      - name: Joining node to cluster
        ansible.builtin.shell: '/usr/bin/kubeadm join --token {{ token | quote }} {{ apiserver | quote }}:{{ k8s_serviceport | quote }} --discovery-token-ca-cert-hash sha256:{{ ca_cert_hash | quote }}'
        args:
          executable: /bin/bash
      - name: Replacing KUBELET_EXTRA_ARGS
        # openrc service file in Alpine Linux uses KUBELET_KUBEADM_ARGS; also needs cgroupfs
        lineinfile:
          line: 'KUBELET_KUBEADM_ARGS="--node-ip {{ ansible_eth1.ipv4.address | quote }} --container-runtime remote --container-runtime-endpoint=/run/containerd/containerd.sock --cgroup-driver=cgroupfs --pod-infra-container-image=k8s.gcr.io/pause:3.5"'
          regexp: '^KUBELET_KUBEADM_ARGS='
          path: /var/lib/kubelet/kubeadm-flags.env
          backup: yes
      - name: Restarting kubelet
        service:
          name: kubelet
          state: restarted
